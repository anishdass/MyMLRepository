{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImplementingFirstMachineLearningAlgorithm.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyONkCZTUUTvrgWqG+cftqJo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anishdass/MyMLRepository/blob/master/ImplementingFirstMachineLearningAlgorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7bkGk-tUekQ",
        "colab_type": "text"
      },
      "source": [
        "# This is the first time I'm getting into sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iz8EeGMUzfy",
        "colab_type": "text"
      },
      "source": [
        "Just importing packages and the inbuilt infamous '20newsgroups' which sklearn has just so that newbies like us don't have to linger around searching for correct datasets, Lol."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkRFeH4DVPlH",
        "colab_type": "text"
      },
      "source": [
        "Our data is stored in the variable 'twenty_train'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2fD4r7oGSEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train=fetch_20newsgroups(subset='train', shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9kMsiBpVtdq",
        "colab_type": "text"
      },
      "source": [
        "  So, twenty_train has got type bunch, Even I don't know what that means. I'm sure that should be somethin interesting. So here I've split the first file of the bunch and printed the first three elements of the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXQbBOnCGrQG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "0ace2118-e2c5-4629-842b-54e42f10d95d"
      },
      "source": [
        "twenty_train.target_names\n",
        "print('\\n'.join(twenty_train.data[0].split('\\n')[:3]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPmnDX2sW4a2",
        "colab_type": "text"
      },
      "source": [
        "#CountVectorizer, the game changer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddxGtF_tXOIH",
        "colab_type": "text"
      },
      "source": [
        "Okay, so what we do here is we convert each word that occurs in the file and assign a vector document-term matrix readble to the machines. But the thing with CountVectorizer is it biases between longer and shorter documents which is not something we want.\n",
        "\n",
        "What do we do?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGLrIkJCG_-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8403d68c-4e2a-4f31-f961-1e6453bda4e3"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect=CountVectorizer()\n",
        "X_train_counts=count_vect.fit_transform(twenty_train.data)\n",
        "X_train_counts.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lReTDpfZX5vB",
        "colab_type": "text"
      },
      "source": [
        "#Here comes the TF-IDF\n",
        "TF- TermFrequency is where the biasing of longer and shorter documents but even now the thing is the commonly used terms like ('The', 'Is', 'On'), will still be present\n",
        "\n",
        "TF-IDF- TermFrequency times inverse document frequency is something that even ignores the commonly called terms mentioned above, Oh libraries! Why you so cool?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42CbBwK2LhEA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "24442fac-e738-4890-a51b-755ce566bbe7"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer=TfidfTransformer()\n",
        "X_train_tfidf=tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK12LQOtdCgV",
        "colab_type": "text"
      },
      "source": [
        "#Running ML Algorithms\n",
        "We'll be using the naive base algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49iriXOUbvHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf=MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-YMuxtNfEm5",
        "colab_type": "text"
      },
      "source": [
        "#Pipelining\n",
        "We do this for convinience, Just to let the program how everything is layered."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhr2n7ZTfObg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "text_clf=Pipeline([('vect', CountVectorizer()),\n",
        "                   ('tfidf', TfidfTransformer()),\n",
        "                   ('clf', MultinomialNB())])\n",
        "\n",
        "text_clf=text_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovolkk4heaYh",
        "colab_type": "text"
      },
      "source": [
        "#Fun time!\n",
        "Here we check the accuracy of the model, Wait, do we have the test dataset yet?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeLURhcvdrYq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8ddf6a79-edb6-46e4-b9f8-3521b4b15c89"
      },
      "source": [
        "import numpy as np\n",
        "twenty_test=fetch_20newsgroups(subset='test', shuffle=True)\n",
        "predicted=text_clf.predict(twenty_test.data)\n",
        "np.mean(predicted==twenty_test.target)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7738980350504514"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWU_n51HhaRa",
        "colab_type": "text"
      },
      "source": [
        "77.38% Accuracy, see that's fun."
      ]
    }
  ]
}